{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"uymKOBRj9EI0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Epoch [1/10], Loss: 6.7944\n","Validation Accuracy: 0.10%\n","Epoch [2/10], Loss: 6.6102\n","Validation Accuracy: 0.28%\n","Epoch [3/10], Loss: 6.4710\n","Validation Accuracy: 0.64%\n","Epoch [4/10], Loss: 6.2312\n","Validation Accuracy: 1.07%\n","Epoch [5/10], Loss: 6.0055\n","Validation Accuracy: 1.73%\n","Epoch [6/10], Loss: 5.8560\n","Validation Accuracy: 2.27%\n","Epoch [7/10], Loss: 5.7275\n","Validation Accuracy: 2.29%\n","Epoch [8/10], Loss: 5.5902\n","Validation Accuracy: 2.70%\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","import os\n","\n","# Ensure your Google Drive is mounted\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","sys.path.append('/content/drive/MyDrive/ColabNotebooks/GhostNet')  # Add the path to your ghostnetN1.py file\n","from ghostnetN1 import GhostNet_N  # Now Python should find the file\n","\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","from PIL import Image, UnidentifiedImageError\n","import os\n","\n","class SafeImageFolder(datasets.ImageFolder):\n","    def __init__(self, root, transform=None):\n","        super().__init__(root=root, transform=transform)\n","\n","    def __getitem__(self, index):\n","        path, target = self.samples[index]\n","        try:\n","            # Try opening the image file\n","            sample = Image.open(path)\n","            sample = sample.convert(\"RGB\")  # Ensure image is in RGB format\n","        except (UnidentifiedImageError, OSError) as e:\n","            print(f\"Skipping corrupted image: {path}\")\n","            #Print out the index of the image that I am skipping. Ignoring the image will keep all other image indexes the same.\n","            raise IndexError(f\"Corrupted image at index {index}, skipping.\")\n","\n","        if self.transform is not None:\n","            sample = self.transform(sample)\n","\n","        return sample, target\n","\n","\n","# Define training configuration and model\n","cfgs = [\n","    [[3, 16, 16, 0, 1, 0]],  # No CBAM, spatial_kernel set to 0\n","    [[3, 48, 24, 0, 2, 0]],  # No CBAM, spatial_kernel set to 0\n","    [[3, 72, 24, 0, 1, 0]],  # No CBAM, spatial_kernel set to 0\n","    [[5, 72, 40, 0.25, 2, 5]],  # CBAM active, spatial_kernel = 5\n","    [[5, 120, 40, 0.25, 1, 7]],  # CBAM active, spatial_kernel = 7\n","    [[3, 240, 80, 0, 2, 0]],  # No CBAM, spatial_kernel set to 0\n","    [[3, 200, 80, 0, 1, 0],  # No CBAM, spatial_kernel set to 0\n","     [3, 184, 80, 0, 1, 0],  # No CBAM, spatial_kernel set to 0\n","     [3, 184, 80, 0, 1, 0],  # No CBAM, spatial_kernel set to 0\n","     [3, 480, 112, 0.25, 1, 5],  # CBAM active, spatial_kernel = 5\n","     [3, 672, 112, 0.25, 1, 5]],  # CBAM active, spatial_kernel = 5\n","    [[5, 672, 160, 0.25, 2, 3]],  # CBAM active, spatial_kernel = 3\n","    [[5, 960, 160, 0, 1, 0],  # No CBAM, spatial_kernel set to 0\n","     [5, 960, 160, 0.25, 1, 3],  # CBAM active, spatial_kernel = 3\n","     [5, 960, 160, 0, 1, 0],  # No CBAM, spatial_kernel set to 0\n","     [5, 960, 160, 0.25, 1, 3]]  # CBAM active, spatial_kernel = 3\n","]\n","\n","# Model initialization\n","model = GhostNet_N(cfgs, num_classes=1000, width=1.0, dropout=0.2)\n","\n","# Dataset and DataLoader setup (load data from Google Drive)\n","train_dir = '/content/drive/MyDrive/ColabNotebooks/GhostNet/ImageNet/dir/train'\n","val_dir = '/content/drive/MyDrive/ColabNotebooks/GhostNet/ImageNet/dir/val'\n","\n","# Define normalization parameters (use ImageNet's mean and std)\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","\n","# Apply transformations for training and validation\n","train_transform = transforms.Compose([\n","    transforms.Resize(256),  # Resize images to 256\n","    transforms.CenterCrop(224),  # Crop to 224x224 for ImageNet models\n","    transforms.ToTensor(),\n","    normalize,\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize(256),  # Resize images to 256\n","    transforms.CenterCrop(224),  # Crop to 224x224 for ImageNet models\n","    transforms.ToTensor(),\n","    normalize,\n","])\n","\n","# Load training and validation datasets using ImageFolder\n","train_dataset = SafeImageFolder(root=train_dir, transform=train_transform)\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n","\n","val_dataset = SafeImageFolder(root=val_dir, transform=val_transform)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n","\n","# Loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","# Training loop\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    model.train()  # Set the model to training mode\n","    running_loss = 0.0\n","    for inputs, targets in train_loader:\n","        optimizer.zero_grad()  # Zero gradients\n","        outputs = model(inputs)  # Forward pass\n","        loss = criterion(outputs, targets)  # Calculate loss\n","        loss.backward()  # Backward pass\n","        optimizer.step()  # Update weights\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n","\n","    # Validation step\n","    model.eval()  # Set the model to evaluation mode\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for inputs, targets in val_loader:\n","            outputs = model(inputs)\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += (predicted == targets).sum().item()\n","\n","        print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")\n","\n","# Save the trained model to Google Drive\n","torch.save(model.state_dict(), '/content/drive/MyDrive/ColabNotebooks/GhostNet/ghostnet_cbamN1.pth')\n","print(\"Model saved to Google Drive as 'ghostnet_cbamN1.pth'\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31048,"status":"ok","timestamp":1741400261060,"user":{"displayName":"Nolan Knight","userId":"18401773510958510497"},"user_tz":300},"id":"Tegetpx3g99D","outputId":"1f4cff5d-3a8a-4c8c-8b94-c08506bfa4b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Successfully loaded a batch: torch.Size([32, 3, 224, 224])\n"]}],"source":["from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","# Define transformations\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","\n","train_dataset = datasets.ImageFolder(\n","    train_dir,\n","    transform=transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.RandomCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n",")\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n","\n","# Try loading a batch\n","try:\n","    images, labels = next(iter(train_loader))\n","    print(f\"✅ Successfully loaded a batch: {images.shape}\")\n","except Exception as e:\n","    print(f\"❌ Error loading training dataset: {e}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyND165PzY7iATAA3/9X/Q4o","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}