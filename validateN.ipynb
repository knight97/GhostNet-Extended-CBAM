{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"176ykN6gTIXuIzDnx3xgM7CogEKJKJGfL","timestamp":1741371552983}],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyOf5jhzbwFCYCASWO30PxLq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"OUdVzB7kcgv9"},"outputs":[],"source":["import os\n","import time\n","import argparse\n","import logging\n","import numpy as np\n","from collections import OrderedDict\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","\n","import sys\n","sys.path.append('/content/drive/MyDrive/ColabNotebooks/GhostNet')  # Add path to ghostnetN1.py\n","from ghostnetN1 import GhostNet_N  # Import Reimplementation Model\n","\n","\n","torch.backends.cudnn.benchmark = True\n","\n","parser = argparse.ArgumentParser(description='PyTorch ImageNet Inference')\n","parser.add_argument('--data', metavar='DIR', default='/cache/data/imagenet/',\n","                    help='path to dataset')\n","parser.add_argument('--output_dir', metavar='DIR', default='/cache/models/',\n","                    help='path to output files')\n","parser.add_argument('-j', '--workers', default=2, type=int, metavar='N',\n","                    help='number of data loading workers (default: 2)')           #The original code uses 4 workers, as the researchers had more processing power to run in parallel, but Colab works better with 2\n","parser.add_argument('-b', '--batch-size', default=256, type=int,\n","                    metavar='N', help='mini-batch size (default: 256)')\n","parser.add_argument('--num-classes', type=int, default=1000,\n","                    help='Number classes in dataset')\n","parser.add_argument('--width', type=float, default=1.0,\n","                    help='Width ratio (default: 1.0)')\n","parser.add_argument('--dropout', type=float, default=0.2, metavar='PCT',\n","                    help='Dropout rate (default: 0.2)')\n","parser.add_argument('--num-gpu', type=int, default=1,\n","                    help='Number of GPUS to use')\n","\n","\n","def main():\n","    args = parser.parse_args()\n","\n","    model = GhostNet_N(num_classes=args.num_classes, width=args.width, dropout=args.dropout)\n","    model.load_state_dict(torch.load('/content/drive/MyDrive/ColabNotebooks/GhostNet/ghostnet_cbam_ImageNet_CBAM_opt.pth'), strict=False)\n","\n","    if args.num_gpu > 1:\n","        model = torch.nn.DataParallel(model, device_ids=list(range(args.num_gpu))).cuda()\n","    elif args.num_gpu < 1:\n","        model = model\n","    else:\n","        model = model.cuda()\n","    print('GhostNet created.')\n","\n","    valdir = '/content/drive/MyDrive/ColabNotebooks/GhostNet/ImageNet/dir/val'\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                          std=[0.229, 0.224, 0.225])\n","    loader = torch.utils.data.DataLoader(\n","        datasets.ImageFolder(valdir, transforms.Compose([\n","            transforms.Resize(256),\n","            transforms.CenterCrop(224),\n","            transforms.ToTensor(),\n","            normalize,\n","        ])),\n","        batch_size=args.batch_size, shuffle=False,\n","        num_workers=args.workers, pin_memory=True)\n","\n","    model.eval()\n","\n","    validate_loss_fn = nn.CrossEntropyLoss().cuda()\n","    eval_metrics = validate(model, loader, validate_loss_fn, args)\n","    print(eval_metrics)\n","\n","\n","def validate(model, loader, loss_fn, args, log_suffix=''):\n","    batch_time_m = AverageMeter()\n","    losses_m = AverageMeter()\n","    top1_m = AverageMeter()\n","    top5_m = AverageMeter()\n","\n","    model.eval()\n","\n","    end = time.time()\n","    last_idx = len(loader) - 1\n","    with torch.no_grad():\n","        for batch_idx, (input, target) in enumerate(loader):\n","            last_batch = batch_idx == last_idx\n","            input = input.cuda()\n","            target = target.cuda()\n","\n","            output = model(input)\n","            if isinstance(output, (tuple, list)):\n","                output = output[0]\n","\n","            loss = loss_fn(output, target)\n","            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","\n","            reduced_loss = loss.data\n","\n","            torch.cuda.synchronize()\n","\n","            losses_m.update(reduced_loss.item(), input.size(0))\n","            top1_m.update(acc1.item(), output.size(0))\n","            top5_m.update(acc5.item(), output.size(0))\n","\n","            batch_time_m.update(time.time() - end)\n","            end = time.time()\n","            if (last_batch or batch_idx % 10 == 0):\n","                log_name = 'Test' + log_suffix\n","                logging.info(\n","                    '{0}: [{1:>4d}/{2}]  '\n","                    'Time: {batch_time.val:.3f} ({batch_time.avg:.3f})  '\n","                    'Loss: {loss.val:>7.4f} ({loss.avg:>6.4f})  '\n","                    'Acc@1: {top1.val:>7.4f} ({top1.avg:>7.4f})  '\n","                    'Acc@5: {top5.val:>7.4f} ({top5.avg:>7.4f})'.format(\n","                        log_name, batch_idx, last_idx, batch_time=batch_time_m,\n","                        loss=losses_m, top1=top1_m, top5=top5_m))\n","\n","    metrics = OrderedDict([('loss', losses_m.avg), ('top1', top1_m.avg), ('top5', top5_m.avg)])\n","\n","    return metrics\n","\n","\n","class AverageMeter:\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","    return [correct[:k].reshape(-1).float().sum(0) * 100. / batch_size for k in topk]     #Colab was unhappy with view, I changed it to reshape to deal better with the dimensionality\n","\n","\n","if __name__ == '__main__':\n","    main()"]}]}